# Tenet 1: Natural Language Is Not a Contract

> **Natural language is an inherently lossy interface.**

In theory, sufficiently capable AI models — especially when layered with agentic tooling — can deliver nearly anything a developer intends *given a perfect prompt or instruction*.

In practice, such a prompt is nearly impossible to achieve.

This is not primarily a limitation of models, reasoning, or comprehension. It is a fundamental limitation of **natural language itself**.

Language contains unavoidable ambiguity:

* Homonyms and polysemes that change meaning by context
* Domain ontologies with overlapping or conflicting nomenclature
* Colloquial shorthand dependent on shared human assumptions
* Idioms and metaphors that collapse under literal interpretation

When a human says:

> “My computer has a bug”

Humans infer software, not an insect, because of shared cultural priors. These priors are **not contractual** and cannot be fully encoded.

Even at the structural level, language is inconsistent:

* Letters change sound based on context (`c` as *s* vs *k*)
* Redundant characters exist (`x` as a compressed phonetic)
* Spelling, pronunciation, and meaning frequently diverge

These are not edge cases. They are core properties of language.
